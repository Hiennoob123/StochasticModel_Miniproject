{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiennoob123/StochasticModel_Miniproject/blob/main/Simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BLOCK 1: Imports and dependencies\n",
        "# Description:\n",
        "#   Load all external libraries needed for discrete-event simulation (SimPy),\n",
        "#   numerical work (NumPy), plotting/animation (Matplotlib), data handling\n",
        "#   (pandas), and display helpers for notebooks.\n",
        "# =============================================================================\n",
        "!pip install simpy\n",
        "import simpy\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 2: Core ED triage system definition\n",
        "# Description:\n",
        "#   Define the EDTriageSystem class, which encapsulates the simulation\n",
        "#   environment, state variables, queues, statistics, and helper utilities.\n",
        "# =============================================================================\n",
        "class EDTriageSystem:\n",
        "    \"\"\"Emergency Department Triage System with Dynamic Staffing\"\"\"\n",
        "\n",
        "    def __init__(self, env, params):\n",
        "        self.env = env\n",
        "        self.params = params\n",
        "\n",
        "        # System state\n",
        "        self.current_staff = params['initial_staff']\n",
        "\n",
        "        # Queue for each triage level - store patient objects\n",
        "        self.queues = {2: [], 3: []}\n",
        "        self.in_service = {2: [], 3: []}  # Store patient objects being served\n",
        "\n",
        "        # Statistics\n",
        "        self.stats = {\n",
        "            'arrivals': 0,\n",
        "            'arrivals_by_level': {2: 0, 3: 0},\n",
        "            'blocked': 0,\n",
        "            'blocked_by_level': {2: 0, 3: 0},\n",
        "            'completed': {2: 0, 3: 0},\n",
        "            'total_reward': 0,\n",
        "            'staff_changes': [],\n",
        "            'queue_history': [],\n",
        "            'service_history': [],\n",
        "            'reward_history': []\n",
        "        }\n",
        "\n",
        "        # Patient counter\n",
        "        self.patient_id = 0\n",
        "\n",
        "        # Events for logging\n",
        "        self.events = []\n",
        "\n",
        "        # All patients for visualization\n",
        "        self.all_patients = {}  # patient_id -> patient object\n",
        "\n",
        "    def log_event(self, message):\n",
        "        \"\"\"Log an event with timestamp\"\"\"\n",
        "        self.events.append((self.env.now, message))\n",
        "\n",
        "    def get_total_queue_size(self):\n",
        "        \"\"\"Get total patients in queue\"\"\"\n",
        "        return sum(len(q) for q in self.queues.values())\n",
        "\n",
        "    def get_total_in_service(self):\n",
        "        \"\"\"Get total patients in service\"\"\"\n",
        "        return sum(len(s) for s in self.in_service.values())\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 3: Patient flow processes (arrival, assignment, service)\n",
        "# Description:\n",
        "#   SimPy processes that generate patient arrivals, assign them to staff based\n",
        "#   on triage priority, and simulate service times and completions.\n",
        "# =============================================================================\n",
        "    def patient_arrival(self):\n",
        "        \"\"\"Generate patient arrivals (Poisson process)\"\"\"\n",
        "        while True:\n",
        "            # Inter-arrival time (exponential)\n",
        "            yield self.env.timeout(np.random.exponential(1.0 / self.params['mu']))\n",
        "\n",
        "            # Assign triage level\n",
        "            rand = np.random.random()\n",
        "            if rand < 0.4: # grouped as urgent\n",
        "                level = 2  # Urgent\n",
        "            else:\n",
        "                level = 3  # Non-urgent\n",
        "\n",
        "            self.patient_id += 1\n",
        "            self.stats['arrivals'] += 1\n",
        "            self.stats['arrivals_by_level'][level] += 1\n",
        "\n",
        "            # Create patient object\n",
        "            patient = {\n",
        "                'id': self.patient_id,\n",
        "                'level': level,\n",
        "                'arrival_time': self.env.now,\n",
        "                'service_start': None,\n",
        "                'completion_time': None,\n",
        "                'status': 'waiting'  # waiting, in_service, completed, blocked\n",
        "            }\n",
        "            self.all_patients[self.patient_id] = patient\n",
        "\n",
        "            # Check queue capacity\n",
        "            if self.get_total_queue_size() >= self.params['M']:\n",
        "                self.stats['blocked'] += 1\n",
        "                self.stats['blocked_by_level'][level] += 1\n",
        "                self.stats['total_reward'] -= self.params['cp']\n",
        "                patient['status'] = 'blocked'\n",
        "                self.log_event(f\"Patient {self.patient_id} (Level {level}) BLOCKED\")\n",
        "            else:\n",
        "                self.queues[level].append(patient)\n",
        "                self.log_event(f\"Patient {self.patient_id} (Level {level}) arrived\")\n",
        "\n",
        "                # Try to assign to staff immediately\n",
        "                self.env.process(self.assign_patient_to_staff())\n",
        "\n",
        "    def assign_patient_to_staff(self):\n",
        "        \"\"\"Assign highest priority patient to available staff\"\"\"\n",
        "        # Keep assigning while we have available staff and waiting patients\n",
        "        while self.get_total_in_service() < self.current_staff:\n",
        "            assigned = False\n",
        "\n",
        "            # Find highest priority patient (Level 2 > 3)\n",
        "            for level in [2, 3]:\n",
        "                if len(self.queues[level]) > 0:\n",
        "                    patient = self.queues[level].pop(0)\n",
        "                    patient['status'] = 'in_service'\n",
        "                    patient['service_start'] = self.env.now\n",
        "                    self.in_service[level].append(patient)\n",
        "\n",
        "                    self.log_event(f\"Patient {patient['id']} (Level {level}) started service\")\n",
        "\n",
        "                    # Start service process\n",
        "                    self.env.process(self.patient_service(patient))\n",
        "                    assigned = True\n",
        "                    break\n",
        "\n",
        "            # If no patients waiting, stop trying\n",
        "            if not assigned:\n",
        "                break\n",
        "\n",
        "        yield self.env.timeout(0)\n",
        "\n",
        "    def patient_service(self, patient):\n",
        "        \"\"\"Service a patient\"\"\"\n",
        "        level = patient['level']\n",
        "\n",
        "        # Service time (exponential)\n",
        "        service_rates = {\n",
        "            2: self.params['lambda2'],\n",
        "            3: self.params['lambda3']\n",
        "        }\n",
        "        service_time = np.random.exponential(1.0 / service_rates[level])\n",
        "\n",
        "        yield self.env.timeout(service_time)\n",
        "\n",
        "        # Complete service\n",
        "        self.in_service[level].remove(patient)\n",
        "        patient['status'] = 'completed'\n",
        "        patient['completion_time'] = self.env.now\n",
        "        self.stats['completed'][level] += 1\n",
        "\n",
        "        # Add reward\n",
        "        rewards = {2: self.params['r2'], 3: self.params['r3']}\n",
        "        self.stats['total_reward'] += rewards[level]\n",
        "\n",
        "        self.log_event(f\"Patient {patient['id']} (Level {level}) completed (+{rewards[level]})\")\n",
        "\n",
        "        # Try to assign next patient\n",
        "        self.env.process(self.assign_patient_to_staff())\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 4: Costs, logging, and state recording\n",
        "# Description:\n",
        "#   Processes for applying hourly maintenance cost, and periodically recording\n",
        "#   queues, service levels, and cumulative reward for later analysis/plots.\n",
        "# =============================================================================\n",
        "    def maintenance_cost(self):\n",
        "        \"\"\"Apply maintenance cost every hour\"\"\"\n",
        "        while True:\n",
        "            yield self.env.timeout(1.0)\n",
        "            cost = self.params['cm'] * self.current_staff\n",
        "            self.stats['total_reward'] -= cost\n",
        "            self.log_event(f\"Maintenance cost: -{cost}\")\n",
        "\n",
        "    def record_state(self):\n",
        "        \"\"\"Record system state periodically\"\"\"\n",
        "        while True:\n",
        "            self.stats['queue_history'].append({\n",
        "                'time': self.env.now,\n",
        "                'q2': len(self.queues[2]),\n",
        "                'q3': len(self.queues[3]),\n",
        "                'total_queue': self.get_total_queue_size()\n",
        "            })\n",
        "\n",
        "            self.stats['service_history'].append({\n",
        "                'time': self.env.now,\n",
        "                'b2': len(self.in_service[2]),\n",
        "                'b3': len(self.in_service[3]),\n",
        "                'total_service': self.get_total_in_service(),\n",
        "                'staff': self.current_staff\n",
        "            })\n",
        "\n",
        "            self.stats['reward_history'].append({\n",
        "                'time': self.env.now,\n",
        "                'reward': self.stats['total_reward']\n",
        "            })\n",
        "\n",
        "            yield self.env.timeout(0.1)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 5: Dynamic staffing control and MDP interface\n",
        "# Description:\n",
        "#   Functions to change staff levels, define the MDP state/action space, and\n",
        "#   implement different staffing policies (static, threshold, reactive, RL).\n",
        "# =============================================================================\n",
        "    def change_staff(self, delta):\n",
        "        \"\"\"Change staff level\"\"\"\n",
        "        new_staff = max(0, min(self.params['Smax'], self.current_staff + delta))\n",
        "\n",
        "        if new_staff > self.current_staff:\n",
        "            # Add staff\n",
        "            increase = new_staff - self.current_staff\n",
        "            old_staff = self.current_staff\n",
        "            self.current_staff = new_staff\n",
        "\n",
        "            # Apply activation cost per new staff\n",
        "            self.stats['total_reward'] -= self.params['ca'] * increase\n",
        "            self.log_event(f\"Activated {increase} new staff (-{self.params['ca'] * increase} cost): {old_staff} → {new_staff}\")\n",
        "\n",
        "            # Try to assign waiting patients to newly available staff\n",
        "            for _ in range(increase):\n",
        "                self.env.process(self.assign_patient_to_staff())\n",
        "\n",
        "        elif new_staff < self.current_staff:\n",
        "            # Decrease staff\n",
        "            # NOTE: In real system, this would only take effect when staff finish service\n",
        "            # For now, we immediately reduce capacity (staff can finish current patients)\n",
        "            decrease = self.current_staff - new_staff\n",
        "            old_staff = self.current_staff\n",
        "            self.current_staff = new_staff\n",
        "            self.log_event(f\"Decreased staff by {decrease}: {old_staff} → {new_staff}\")\n",
        "\n",
        "        self.stats['staff_changes'].append({\n",
        "            'time': self.env.now,\n",
        "            'staff': self.current_staff,\n",
        "            'delta': delta\n",
        "        })\n",
        "\n",
        "        # Verify constraint: total in service should not exceed staff\n",
        "        total_in_service = self.get_total_in_service()\n",
        "        if total_in_service > self.current_staff:\n",
        "            self.log_event(f\"WARNING: {total_in_service} patients in service but only {self.current_staff} staff!\")\n",
        "\n",
        "    def get_state(self):\n",
        "        \"\"\"Get current MDP state: (Q2, Q3, B2, B3, S)\"\"\"\n",
        "        return (\n",
        "            len(self.queues[2]),\n",
        "            len(self.queues[3]),\n",
        "            len(self.in_service[2]),\n",
        "            len(self.in_service[3]),\n",
        "            self.current_staff\n",
        "        )\n",
        "\n",
        "    def get_valid_actions(self):\n",
        "        \"\"\"Get valid actions: can decrease by any amount or increase by 1\"\"\"\n",
        "        actions = [0]  # Always can do nothing\n",
        "\n",
        "        # Can increase by 1 if not at max\n",
        "        if self.current_staff < self.params['Smax']:\n",
        "            actions.append(1)\n",
        "\n",
        "        # Can decrease by any amount from -1 to -S_t\n",
        "        for decrease in range(1, self.current_staff + 1):\n",
        "            actions.append(-decrease)\n",
        "\n",
        "        return actions\n",
        "\n",
        "    def staffing_policy(self, policy_type='static', rl_agent=None):\n",
        "        \"\"\"Apply staffing policy\"\"\"\n",
        "        while True:\n",
        "            yield self.env.timeout(1.0)  # Decision every hour\n",
        "\n",
        "            if policy_type == 'static':\n",
        "                pass\n",
        "\n",
        "            elif policy_type == 'threshold':\n",
        "                total_queue = self.get_total_queue_size()\n",
        "\n",
        "                if total_queue > self.params['M'] * 0.7 and self.current_staff < self.params['Smax']:\n",
        "                    self.change_staff(1)\n",
        "                elif total_queue < self.params['M'] * 0.3 and self.current_staff > 1:\n",
        "                    self.change_staff(-1)\n",
        "\n",
        "            elif policy_type == 'reactive':\n",
        "                # No critical queue for this policy\n",
        "                total_queue = self.get_total_queue_size()\n",
        "\n",
        "                if total_queue > self.params['M'] * 0.8:\n",
        "                    if self.current_staff < self.params['Smax']:\n",
        "                        self.change_staff(1)\n",
        "                elif total_queue < 5:\n",
        "                    if self.current_staff > 2:\n",
        "                        self.change_staff(-1)\n",
        "\n",
        "            elif policy_type == 'rl' and rl_agent is not None:\n",
        "                # Get current state\n",
        "                state = self.get_state()\n",
        "                valid_actions = self.get_valid_actions()\n",
        "\n",
        "                # Get action from RL agent\n",
        "                action = rl_agent.select_action(state, valid_actions)\n",
        "\n",
        "                # Apply action\n",
        "                if action != 0:\n",
        "                    self.change_staff(action)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 6: Live visual simulation (animation)\n",
        "# Description:\n",
        "#   Function to run the ED triage system in real time and display an animated\n",
        "#   visualization of queues, treatment area, and key statistics using Matplotlib.\n",
        "# =============================================================================\n",
        "def live_visual_simulation(params, sim_time=50, policy='reactive', rl_agent=None):\n",
        "    \"\"\"\n",
        "    Live visual simulation with animated patients as dots\n",
        "    Shows patients queueing and being served in real-time\n",
        "    \"\"\"\n",
        "    from matplotlib.animation import FuncAnimation\n",
        "    from IPython.display import HTML\n",
        "\n",
        "    env = simpy.Environment()\n",
        "    system = EDTriageSystem(env, params)\n",
        "\n",
        "    # Start processes\n",
        "    env.process(system.patient_arrival())\n",
        "    env.process(system.maintenance_cost())\n",
        "    env.process(system.record_state())\n",
        "    env.process(system.staffing_policy(policy, rl_agent))\n",
        "\n",
        "    # Setup figure\n",
        "    fig = plt.figure(figsize=(16, 10))\n",
        "    gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    # Main visualization area - ED Layout\n",
        "    ax_main = fig.add_subplot(gs[:2, :2])\n",
        "\n",
        "    # Statistics plots\n",
        "    ax_queue = fig.add_subplot(gs[0, 2])\n",
        "    ax_reward = fig.add_subplot(gs[1, 2])\n",
        "    ax_stats = fig.add_subplot(gs[2, :])\n",
        "\n",
        "    # Colors for triage levels\n",
        "    colors = {2: 'orange', 3: 'gold'}\n",
        "\n",
        "    def draw_ed_layout(ax):\n",
        "        \"\"\"Draw the ED layout background\"\"\"\n",
        "        ax.clear()\n",
        "        ax.set_xlim(0, 10)\n",
        "        ax.set_ylim(0, 10)\n",
        "        ax.set_aspect('equal')\n",
        "        ax.axis('off')\n",
        "\n",
        "        # Title\n",
        "        ax.text(5, 9.5, 'Emergency Department - Live Simulation',\n",
        "                ha='center', fontsize=14, fontweight='bold')\n",
        "        ax.text(5, 9, f'Time: {env.now:.1f}h | Policy: {policy} | Staff: {system.current_staff}/{params[\"Smax\"]}',\n",
        "                ha='center', fontsize=10)\n",
        "\n",
        "        # Entrance\n",
        "        entrance = mpatches.Rectangle((0, 7), 1, 2, linewidth=2,\n",
        "                                     edgecolor='black', facecolor='lightblue', alpha=0.3)\n",
        "        ax.add_patch(entrance)\n",
        "        ax.text(0.5, 8, 'ENTRANCE', ha='center', va='center', fontsize=8, fontweight='bold')\n",
        "\n",
        "        # Queue areas\n",
        "        queue_y_positions = {2: 7.5, 3: 5.5}\n",
        "        queue_labels = {2: 'URGENT', 3: 'NON-URGENT'}\n",
        "\n",
        "        for level in [2, 3]:\n",
        "            y_pos = queue_y_positions[level]\n",
        "            queue_box = mpatches.Rectangle((1.5, y_pos-0.4), 4, 0.8, linewidth=2,\n",
        "                                          edgecolor=colors[level], facecolor=colors[level], alpha=0.1)\n",
        "            ax.add_patch(queue_box)\n",
        "            ax.text(1.2, y_pos, f'L{level}:', ha='right', va='center',\n",
        "                   fontsize=9, fontweight='bold', color=colors[level])\n",
        "            ax.text(3.5, y_pos+0.5, queue_labels[level], ha='center', va='bottom',\n",
        "                   fontsize=8, color=colors[level], fontweight='bold')\n",
        "\n",
        "        # Treatment area\n",
        "        treatment = mpatches.Rectangle((6.5, 2.5), 3, 5.5, linewidth=2,\n",
        "                                      edgecolor='green', facecolor='lightgreen', alpha=0.2)\n",
        "        ax.add_patch(treatment)\n",
        "        ax.text(8, 7.5, 'TREATMENT AREA', ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "        # Staff positions (beds)\n",
        "        staff_positions = []\n",
        "        for i in range(params['Smax']):\n",
        "            row = i // 3\n",
        "            col = i % 3\n",
        "            x = 7 + col * 0.8\n",
        "            y = 6.5 - row * 0.8\n",
        "            staff_positions.append((x, y))\n",
        "\n",
        "            # Draw bed\n",
        "            if i < system.current_staff:\n",
        "                bed = mpatches.Circle((x, y), 0.15, color='green', alpha=0.3)\n",
        "            else:\n",
        "                bed = mpatches.Circle((x, y), 0.15, color='gray', alpha=0.2)\n",
        "            ax.add_patch(bed)\n",
        "\n",
        "        return staff_positions, queue_y_positions\n",
        "\n",
        "    def draw_patients(ax, staff_positions, queue_y_positions):\n",
        "        \"\"\"Draw patients as colored dots\"\"\"\n",
        "        # Draw queue patients\n",
        "        for level in [2, 3]:\n",
        "            y_pos = queue_y_positions[level]\n",
        "            queue = system.queues[level]\n",
        "\n",
        "            for idx, patient in enumerate(queue):\n",
        "                x = 2 + (idx % 10) * 0.35\n",
        "                y = y_pos + (idx // 10) * 0.15\n",
        "\n",
        "                circle = mpatches.Circle((x, y), 0.12, color=colors[level],\n",
        "                                        edgecolor='black', linewidth=1, zorder=10)\n",
        "                ax.add_patch(circle)\n",
        "\n",
        "                # Patient ID\n",
        "                ax.text(x, y, str(patient['id']), ha='center', va='center',\n",
        "                       fontsize=6, color='white', fontweight='bold', zorder=11)\n",
        "\n",
        "        # Draw patients in service\n",
        "        service_idx = 0\n",
        "        for level in [2, 3]:\n",
        "            for patient in system.in_service[level]:\n",
        "                if service_idx < len(staff_positions):\n",
        "                    x, y = staff_positions[service_idx]\n",
        "\n",
        "                    circle = mpatches.Circle((x, y), 0.15, color=colors[level],\n",
        "                                           edgecolor='darkgreen', linewidth=2, zorder=10)\n",
        "                    ax.add_patch(circle)\n",
        "\n",
        "                    ax.text(x, y, str(patient['id']), ha='center', va='center',\n",
        "                           fontsize=7, color='white', fontweight='bold', zorder=11)\n",
        "\n",
        "                    service_idx += 1\n",
        "\n",
        "        # Legend\n",
        "        legend_elements = [\n",
        "            mpatches.Patch(color='orange', label='Level 2 (Urgent)'),\n",
        "            mpatches.Patch(color='gold', label='Level 3 (Non-urgent)')\n",
        "        ]\n",
        "        ax.legend(handles=legend_elements, loc='lower left', fontsize=8)\n",
        "\n",
        "    def update_statistics_plots():\n",
        "        \"\"\"Update the statistics plots\"\"\"\n",
        "        if len(system.stats['queue_history']) < 2:\n",
        "            return\n",
        "\n",
        "        df_queue = pd.DataFrame(system.stats['queue_history'])\n",
        "        df_reward = pd.DataFrame(system.stats['reward_history'])\n",
        "\n",
        "        # Queue plot\n",
        "        ax_queue.clear()\n",
        "        ax_queue.plot(df_queue['time'], df_queue['q2'], color='orange', linewidth=2, label='L2')\n",
        "        ax_queue.plot(df_queue['time'], df_queue['q3'], color='gold', linewidth=2, label='L3')\n",
        "        ax_queue.axhline(y=params['M'], color='red', linestyle=':', label='Capacity')\n",
        "        ax_queue.set_xlabel('Time (h)', fontsize=8)\n",
        "        ax_queue.set_ylabel('Queue Size', fontsize=8)\n",
        "        ax_queue.set_title('Queue Over Time', fontsize=9, fontweight='bold')\n",
        "        ax_queue.legend(fontsize=7)\n",
        "        ax_queue.grid(True, alpha=0.3)\n",
        "        ax_queue.tick_params(labelsize=7)\n",
        "\n",
        "        # Reward plot\n",
        "        ax_reward.clear()\n",
        "        ax_reward.plot(df_reward['time'], df_reward['reward'], 'purple', linewidth=2)\n",
        "        ax_reward.set_xlabel('Time (h)', fontsize=8)\n",
        "        ax_reward.set_ylabel('Reward', fontsize=8)\n",
        "        ax_reward.set_title('Cumulative Reward', fontweight='bold')\n",
        "        ax_reward.grid(True, alpha=0.3)\n",
        "        ax_reward.tick_params(labelsize=7)\n",
        "\n",
        "        # Statistics bar\n",
        "        ax_stats.clear()\n",
        "        stats_labels = ['Arrivals', 'In Queue', 'In Service', 'Completed', 'Blocked']\n",
        "        stats_values = [\n",
        "            system.stats['arrivals'],\n",
        "            system.get_total_queue_size(),\n",
        "            system.get_total_in_service(),\n",
        "            sum(system.stats['completed'].values()),\n",
        "            system.stats['blocked']\n",
        "        ]\n",
        "        stats_colors = ['blue', 'orange', 'green', 'lightgreen', 'red']\n",
        "\n",
        "        bars = ax_stats.bar(stats_labels, stats_values, color=stats_colors, alpha=0.7, edgecolor='black')\n",
        "        ax_stats.set_ylabel('Count', fontsize=9)\n",
        "        ax_stats.set_title(f'Statistics | Reward: {system.stats[\"total_reward\"]:.2f}',\n",
        "                          fontsize=10, fontweight='bold')\n",
        "        ax_stats.grid(True, alpha=0.3, axis='y')\n",
        "        ax_stats.tick_params(labelsize=8)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax_stats.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                         f'{int(height)}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
        "\n",
        "    def animate(frame):\n",
        "        \"\"\"Animation function\"\"\"\n",
        "        # Run simulation for a small time step\n",
        "        env.run(until=env.now + 0.2)\n",
        "\n",
        "        # Redraw everything\n",
        "        staff_positions, queue_y_positions = draw_ed_layout(ax_main)\n",
        "        draw_patients(ax_main, staff_positions, queue_y_positions)\n",
        "        update_statistics_plots()\n",
        "\n",
        "        return ax_main, ax_queue, ax_reward, ax_stats\n",
        "\n",
        "    # Initial draw\n",
        "    staff_positions, queue_y_positions = draw_ed_layout(ax_main)\n",
        "\n",
        "    # Create animation\n",
        "    frames = int(sim_time / 0.2)\n",
        "    anim = FuncAnimation(fig, animate, frames=frames, interval=200, blit=False, repeat=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return anim, system\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 7: Q-learning agent\n",
        "# Description:\n",
        "#   Define a tabular Q-Learning agent that interacts with the MDP defined by\n",
        "#   EDTriageSystem, maintaining a Q-table and providing action-selection\n",
        "#   and update rules.\n",
        "# =============================================================================\n",
        "class QLearningAgent:\n",
        "    \"\"\"\n",
        "    Q-Learning agent for dynamic staffing control\n",
        "    State: (Q2, Q3, B2, B3, S)\n",
        "    Action: {-S, ..., -1, 0, +1}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, learning_rate=0.1, discount_factor=0.95, epsilon=1):\n",
        "        self.params = params\n",
        "        self.alpha = learning_rate  # Learning rate\n",
        "        self.gamma = discount_factor  # Discount factor\n",
        "        self.epsilon = epsilon  # Exploration rate\n",
        "\n",
        "        # Q-table: Q(state, action) -> value\n",
        "        self.q_table = {}\n",
        "\n",
        "        # For tracking\n",
        "        self.episode_rewards = []\n",
        "        self.episode_states = []\n",
        "        self.episode_actions = []\n",
        "        self.episodes = 0\n",
        "\n",
        "    # Decay epsilon function\n",
        "    def decay_epsilon(self, episode):\n",
        "        self.epsilon = max(0.1, 1.0 - 0.000099 * episode)\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        \"\"\"Get Q-value for state-action pair\"\"\"\n",
        "        return self.q_table.get((state, action), 0.0)\n",
        "\n",
        "    def select_action(self, state, valid_actions, training=True):\n",
        "        \"\"\"Select action using epsilon-greedy policy\"\"\"\n",
        "        # Update epsidlon\n",
        "        self.episodes += 1\n",
        "        self.decay_epsilon(self.episodes)\n",
        "\n",
        "        if training and np.random.random() < self.epsilon:\n",
        "            # Improve exploration by increase the chance of choosing +1.\n",
        "            if 1 in valid_actions:\n",
        "                current_len = len(valid_actions)\n",
        "                for i in range(current_len // 2):\n",
        "                    valid_actions.append(1)\n",
        "\n",
        "            # Explore: random action\n",
        "            return np.random.choice(valid_actions)\n",
        "        else:\n",
        "            # Exploit: best action\n",
        "            q_values = [self.get_q_value(state, a) for a in valid_actions]\n",
        "            max_q = max(q_values)\n",
        "\n",
        "            # Handle ties randomly\n",
        "            best_actions = [a for a, q in zip(valid_actions, q_values) if q == max_q]\n",
        "            return np.random.choice(best_actions)\n",
        "\n",
        "    def update_q_value(self, state, action, reward, next_state, next_valid_actions):\n",
        "        \"\"\"Update Q-value using Q-learning update rule\"\"\"\n",
        "        current_q = self.get_q_value(state, action)\n",
        "\n",
        "        # Get max Q-value for next state\n",
        "        if next_valid_actions:\n",
        "            next_q_values = [self.get_q_value(next_state, a) for a in next_valid_actions]\n",
        "            max_next_q = max(next_q_values)\n",
        "        else:\n",
        "            max_next_q = 0.0\n",
        "\n",
        "        # Q-learning update\n",
        "        new_q = current_q + self.alpha * (reward + self.gamma * max_next_q - current_q)\n",
        "        self.q_table[(state, action)] = new_q\n",
        "\n",
        "    def get_policy(self):\n",
        "        \"\"\"Extract policy from Q-table\"\"\"\n",
        "        policy = {}\n",
        "\n",
        "        for (state, action), q_value in self.q_table.items():\n",
        "            if state not in policy or q_value > policy[state][1]:\n",
        "                policy[state] = (action, q_value)\n",
        "\n",
        "        return policy\n",
        "\n",
        "    def save_policy(self, filename):\n",
        "        \"\"\"Save Q-table to file\"\"\"\n",
        "        import pickle\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(self.q_table, f)\n",
        "\n",
        "    def load_policy(self, filename):\n",
        "        \"\"\"Load Q-table from file\"\"\"\n",
        "        import pickle\n",
        "        with open(filename, 'rb') as f:\n",
        "            self.q_table = pickle.load(f)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 8: Simulation-based RL trainer\n",
        "# Description:\n",
        "#   Class that uses the simulation (EDTriageSystem + SimPy) to generate\n",
        "#   episodes, let the RL agent interact, update Q-values, and track training\n",
        "#   metrics and progress.\n",
        "# =============================================================================\n",
        "class SimulationBasedRLTrainer:\n",
        "    \"\"\"Train RL agent using simulation-based approach\"\"\"\n",
        "\n",
        "    def __init__(self, params, agent):\n",
        "        self.params = params\n",
        "        self.agent = agent\n",
        "        self.training_history = []\n",
        "\n",
        "    def run_episode(self, episode_length=50, verbose=False):\n",
        "        \"\"\"Run one training episode\"\"\"\n",
        "        env = simpy.Environment()\n",
        "        system = EDTriageSystem(env, self.params)\n",
        "\n",
        "        # Start basic processes (no staffing policy yet)\n",
        "        env.process(system.patient_arrival())\n",
        "        env.process(system.maintenance_cost())\n",
        "        env.process(system.record_state())\n",
        "\n",
        "        # Manual RL control process\n",
        "        env.process(self.rl_control_process(env, system, episode_length))\n",
        "\n",
        "        # Run simulation\n",
        "        env.run(until=episode_length)\n",
        "\n",
        "        total_reward = system.stats['total_reward']\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Episode completed: Reward = {total_reward:.2f}, \"\n",
        "                  f\"Arrivals = {system.stats['arrivals']}, \"\n",
        "                  f\"Blocked = {system.stats['blocked']}, \"\n",
        "                  f\"Completed = {sum(system.stats['completed'].values())}\")\n",
        "\n",
        "        return total_reward, system\n",
        "\n",
        "    def rl_control_process(self, env, system, episode_length):\n",
        "        \"\"\"Process for RL agent to make decisions\"\"\"\n",
        "        prev_state = None\n",
        "        prev_action = None\n",
        "        prev_reward = 0\n",
        "\n",
        "        while env.now < episode_length:\n",
        "            yield env.timeout(1.0)  # Decision every hour\n",
        "\n",
        "            # Get current state\n",
        "            current_state = system.get_state()\n",
        "            valid_actions = system.get_valid_actions()\n",
        "\n",
        "            # Calculate reward from last step\n",
        "            current_reward = system.stats['total_reward']\n",
        "            step_reward = current_reward - prev_reward\n",
        "\n",
        "            # Update Q-value if we have a previous transition\n",
        "            if prev_state is not None:\n",
        "                self.agent.update_q_value(\n",
        "                    prev_state, prev_action, step_reward,\n",
        "                    current_state, valid_actions\n",
        "                )\n",
        "\n",
        "            # Select and execute action\n",
        "            action = self.agent.select_action(current_state, valid_actions, training=True)\n",
        "\n",
        "            if action != 0:\n",
        "                system.change_staff(action)\n",
        "\n",
        "            # Store for next update\n",
        "            prev_state = current_state\n",
        "            prev_action = action\n",
        "            prev_reward = current_reward\n",
        "\n",
        "    def train(self, num_episodes=100, episode_length=50, verbose_interval=10):\n",
        "        \"\"\"Train the agent over multiple episodes\"\"\"\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TRAINING RL AGENT\")\n",
        "        print(f\"Episodes: {num_episodes} | Episode Length: {episode_length}h\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        episode_rewards = []\n",
        "\n",
        "        for episode in range(num_episodes):\n",
        "            reward, system = self.run_episode(episode_length, verbose=False)\n",
        "            episode_rewards.append(reward)\n",
        "\n",
        "            self.training_history.append({\n",
        "                'episode': episode,\n",
        "                'reward': reward,\n",
        "                'arrivals': system.stats['arrivals'],\n",
        "                'blocked': system.stats['blocked'],\n",
        "                'completed': sum(system.stats['completed'].values()),\n",
        "                'q_table_size': len(self.agent.q_table)\n",
        "            })\n",
        "\n",
        "            if (episode + 1) % verbose_interval == 0:\n",
        "                avg_reward = np.mean(episode_rewards[-verbose_interval:])\n",
        "                avg_blocked = np.mean([h['blocked'] for h in self.training_history[-verbose_interval:]])\n",
        "                print(f\"Episode {episode+1}/{num_episodes} | \"\n",
        "                      f\"Avg Reward: {avg_reward:.2f} | \"\n",
        "                      f\"Avg Blocked: {avg_blocked:.1f} | \"\n",
        "                      f\"Q-table: {len(self.agent.q_table)}\")\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TRAINING COMPLETE\")\n",
        "        print(f\"Final Q-table size: {len(self.agent.q_table)}\")\n",
        "        print(f\"Average reward (last 10 episodes): {np.mean(episode_rewards[-10:]):.2f}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        return episode_rewards\n",
        "\n",
        "    def plot_training_progress(self):\n",
        "        \"\"\"Plot training progress\"\"\"\n",
        "        df = pd.DataFrame(self.training_history)\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "        # Reward over episodes\n",
        "        axes[0, 0].plot(df['episode'], df['reward'], linewidth=2, alpha=0.6)\n",
        "        # Moving average\n",
        "        window = min(10, len(df) // 10)\n",
        "        if window > 0:\n",
        "            moving_avg = df['reward'].rolling(window=window).mean()\n",
        "            axes[0, 0].plot(df['episode'], moving_avg, 'r-', linewidth=2, label=f'Moving Avg ({window})')\n",
        "        axes[0, 0].set_xlabel('Episode')\n",
        "        axes[0, 0].set_ylabel('Total Reward')\n",
        "        axes[0, 0].set_title('Learning Progress - Reward', fontweight='bold')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Blocked patients\n",
        "        axes[0, 1].plot(df['episode'], df['blocked'], 'r-', linewidth=2, alpha=0.6)\n",
        "        if window > 0:\n",
        "            moving_avg = df['blocked'].rolling(window=window).mean()\n",
        "            axes[0, 1].plot(df['episode'], moving_avg, 'darkred', linewidth=2, label=f'Moving Avg ({window})')\n",
        "        axes[0, 1].set_xlabel('Episode')\n",
        "        axes[0, 1].set_ylabel('Blocked Patients')\n",
        "        axes[0, 1].set_title('Blocked Patients Over Time', fontweight='bold')\n",
        "        axes[0, 1].legend()\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Completed services\n",
        "        axes[1, 0].plot(df['episode'], df['completed'], 'g-', linewidth=2, alpha=0.6)\n",
        "        if window > 0:\n",
        "            moving_avg = df['completed'].rolling(window=window).mean()\n",
        "            axes[1, 0].plot(df['episode'], moving_avg, 'darkgreen', linewidth=2, label=f'Moving Avg ({window})')\n",
        "        axes[1, 0].set_xlabel('Episode')\n",
        "        axes[1, 0].set_ylabel('Completed Services')\n",
        "        axes[1, 0].set_title('Completed Services Over Time', fontweight='bold')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Q-table growth\n",
        "        axes[1, 1].plot(df['episode'], df['q_table_size'], 'purple', linewidth=2)\n",
        "        axes[1, 1].set_xlabel('Episode')\n",
        "        axes[1, 1].set_ylabel('Q-table Size')\n",
        "        axes[1, 1].set_title('Q-table Growth', fontweight='bold')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 9: Policy comparison wrapper\n",
        "# Description:\n",
        "#   High-level function to train the RL agent, evaluate all policies (static,\n",
        "#   threshold, reactive, RL), print summary metrics, and visualize comparisons.\n",
        "# =============================================================================\n",
        "def compare_all_policies(params, sim_time=5000):\n",
        "    \"\"\"Compare all policies including RL\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"COMPARING ALL POLICIES\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # Train RL agent first\n",
        "    print(\"Training RL agent...\")\n",
        "    agent = QLearningAgent(params, learning_rate=0.1, discount_factor=0.95, epsilon=0.2)\n",
        "    trainer = SimulationBasedRLTrainer(params, agent)\n",
        "    episode_rewards = trainer.train(num_episodes=10000, episode_length=50, verbose_interval=500)\n",
        "    trainer.plot_training_progress()\n",
        "\n",
        "    # Set to exploitation mode\n",
        "    agent.epsilon = 0.0  # No exploration during evaluation\n",
        "\n",
        "    policies = {\n",
        "        'static': None,\n",
        "        'threshold': None,\n",
        "        'reactive': None,\n",
        "        'rl': agent\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"EVALUATING POLICIES\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    for policy_name, rl_agent in policies.items():\n",
        "        # Run simulation\n",
        "        env = simpy.Environment()\n",
        "        system = EDTriageSystem(env, params)\n",
        "\n",
        "        env.process(system.patient_arrival())\n",
        "        env.process(system.maintenance_cost())\n",
        "        env.process(system.record_state())\n",
        "        env.process(system.staffing_policy(policy_name if policy_name != 'rl' else 'rl', rl_agent))\n",
        "\n",
        "        env.run(until=sim_time)\n",
        "\n",
        "        results[policy_name] = {\n",
        "            'total_reward': system.stats['total_reward'],\n",
        "            'completed': sum(system.stats['completed'].values()),\n",
        "            'blocked': system.stats['blocked'],\n",
        "            'blocking_rate': system.stats['blocked']/max(1, system.stats['arrivals'])*100,\n",
        "            'avg_queue': np.mean([h['total_queue'] for h in system.stats['queue_history']]) if system.stats['queue_history'] else 0,\n",
        "            'avg_staff': np.mean([h['staff'] for h in system.stats['service_history']]) if system.stats['service_history'] else params['initial_staff']\n",
        "        }\n",
        "\n",
        "        print(f\"Policy: {policy_name:12s} | Reward: {results[policy_name]['total_reward']:8.2f} | \"\n",
        "              f\"Completed: {results[policy_name]['completed']:4d} | \"\n",
        "              f\"Blocked: {results[policy_name]['blocked']:3d} ({results[policy_name]['blocking_rate']:.1f}%)者に\")\n",
        "\n",
        "    # Plot comparison\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    fig.suptitle('Policy Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "    policy_names = list(results.keys())\n",
        "    colors_map = {'static': 'gray', 'threshold': 'blue', 'reactive': 'green', 'rl': 'red'}\n",
        "    colors = [colors_map[p] for p in policy_names]\n",
        "\n",
        "    # Total reward\n",
        "    axes[0, 0].bar(policy_names, [results[p]['total_reward'] for p in policy_names], color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[0, 0].set_ylabel('Total Reward')\n",
        "    axes[0, 0].set_title('Total Reward', fontweight='bold')\n",
        "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Completed services\n",
        "    axes[0, 1].bar(policy_names, [results[p]['completed'] for p in policy_names], color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[0, 1].set_ylabel('Completed Services')\n",
        "    axes[0, 1].set_title('Completed Services', fontweight='bold')\n",
        "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Blocking rate\n",
        "    axes[0, 2].bar(policy_names, [results[p]['blocking_rate'] for p in policy_names], color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[0, 2].set_ylabel('Blocking Rate (%)')\n",
        "    axes[0, 2].set_title('Blocking Rate', fontweight='bold')\n",
        "    axes[0, 2].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Blocked patients\n",
        "    axes[1, 0].bar(policy_names, [results[p]['blocked'] for p in policy_names], color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[1, 0].set_ylabel('Blocked Patients')\n",
        "    axes[1, 0].set_title('Blocked Patients', fontweight='bold')\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Average queue size\n",
        "    axes[1, 1].bar(policy_names, [results[p]['avg_queue'] for p in policy_names], color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[1, 1].set_ylabel('Average Queue Size')\n",
        "    axes[1, 1].set_title('Average Queue Size', fontweight='bold')\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Average staff\n",
        "    axes[1, 2].bar(policy_names, [results[p]['avg_staff'] for p in policy_names], color=colors, alpha=0.7, edgecolor='black')\n",
        "    axes[1, 2].set_ylabel('Average Staff')\n",
        "    axes[1, 2].set_title('Average Staff Level', fontweight='bold')\n",
        "    axes[1, 2].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return results, trained_agent\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# BLOCK 10: Main entry point and default parameters\n",
        "# Description:\n",
        "#   Script entry for running the full experiment: define base parameters,\n",
        "#   train and compare all policies, and (optionally) run a live visualization.\n",
        "# =============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Parameters\n",
        "    params = {\n",
        "        'mu': 10.0,           # Arrival rate per hour\n",
        "        'lambda2': 4.0,       # Service rate for urgent\n",
        "        'lambda3': 6.0,       # Service rate for non-urgent\n",
        "        'M': 20,              # Queue capacity\n",
        "        'Smax': 10,           # Max staff\n",
        "        'initial_staff': 2,   # Initial staff\n",
        "        'r2': 50,             # Reward for urgent\n",
        "        'r3': 20,             # Reward for non-urgent\n",
        "        'cm': 10,             # Maintenance cost per staff per hour\n",
        "        'ca': 50,             # Activation cost per staff\n",
        "        'cp': 100            # Blocking penalty per patient\n",
        "    }\n",
        "\n",
        "    # ========================================================================\n",
        "    # OPTION 1: Train and compare all policies\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SIMULATION-BASED REINFORCEMENT LEARNING\")\n",
        "    print(\"=\"*70)\n",
        "    results, trained_agent = compare_all_policies(params, sim_time=5000)\n",
        "\n",
        "    # ========================================================================\n",
        "    # OPTION 2: Run live visual simulation with trained RL agent\n",
        "    # (commented out by default)\n",
        "    # ========================================================================\n",
        "    # print(\"\\n\" + \"=\"*70)\n",
        "    # print(\"LIVE VISUAL SIMULATION WITH RL POLICY\")\n",
        "    # print(\"=\"*70)\n",
        "    # print(\"\\nRunning visual simulation with trained RL agent...\")\n",
        "    # print(\"- Patients shown as colored dots\")\n",
        "    # print(\"- RL agent makes staffing decisions every hour\")\n",
        "    # print(\"=\"*70)\n",
        "\n",
        "    # For Jupyter notebook:\n",
        "    # %matplotlib notebook  # or %matplotlib widget\n",
        "    # anim, system = live_visual_simulation(params, sim_time=50, policy='rl', rl_agent=trained_agent)\n",
        "\n",
        "    # plt.show()\n",
        "\n",
        "    # print(\"\\n\" + \"=\"*70)\n",
        "    # print(\"SIMULATION COMPLETE\")\n",
        "    # print(\"=\"*70)\n",
        "    # print(f\"Final Statistics with RL Policy:\")\n",
        "    # print(f\"  Total Arrivals: {system.stats['arrivals']}\")\n",
        "    # if system.stats['arrivals'] > 0:\n",
        "    #     print(f\"  Total Blocked: {system.stats['blocked']} ({system.stats['blocked']/system.stats['arrivals']*100:.2f}%)\")\n",
        "    # else:\n",
        "    #     print(f\"  Total Blocked: {system.stats['blocked']} (N/A - no arrivals)\")\n",
        "    # print(f\"  Total Completed: {sum(system.stats['completed'].values())}\")\n",
        "    # print(f\"  Final Reward: {system.stats['total_reward']:.2f}\")\n",
        "    # print(f\"  Q-table size: {len(trained_agent.q_table)} states\")\n",
        "    # print(\"=\"*70)"
      ],
      "metadata": {
        "id": "xdkOOiK4OHes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caeffd56-2f04-41c4-e3ac-93d479596852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: simpy in /usr/local/lib/python3.12/dist-packages (4.1.1)\n",
            "\n",
            "======================================================================\n",
            "SIMULATION-BASED REINFORCEMENT LEARNING\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "COMPARING ALL POLICIES\n",
            "======================================================================\n",
            "\n",
            "Training RL agent...\n",
            "\n",
            "======================================================================\n",
            "TRAINING RL AGENT\n",
            "Episodes: 10000 | Episode Length: 50h\n",
            "======================================================================\n",
            "\n",
            "Episode 500/10000 | Avg Reward: 8144.28 | Avg Blocked: 32.9 | Q-table: 1680\n",
            "Episode 1000/10000 | Avg Reward: 10881.00 | Avg Blocked: 9.9 | Q-table: 1971\n",
            "Episode 1500/10000 | Avg Reward: 10940.26 | Avg Blocked: 8.8 | Q-table: 2156\n",
            "Episode 2000/10000 | Avg Reward: 11027.00 | Avg Blocked: 8.3 | Q-table: 2328\n",
            "Episode 2500/10000 | Avg Reward: 10978.36 | Avg Blocked: 8.3 | Q-table: 2463\n",
            "Episode 3000/10000 | Avg Reward: 11106.16 | Avg Blocked: 7.7 | Q-table: 2569\n",
            "Episode 3500/10000 | Avg Reward: 11165.70 | Avg Blocked: 7.3 | Q-table: 2672\n",
            "Episode 4000/10000 | Avg Reward: 11140.40 | Avg Blocked: 9.2 | Q-table: 2755\n",
            "Episode 4500/10000 | Avg Reward: 11442.14 | Avg Blocked: 8.1 | Q-table: 2836\n",
            "Episode 5000/10000 | Avg Reward: 11306.28 | Avg Blocked: 8.3 | Q-table: 2910\n",
            "Episode 5500/10000 | Avg Reward: 11399.26 | Avg Blocked: 8.5 | Q-table: 2970\n",
            "Episode 6000/10000 | Avg Reward: 11506.66 | Avg Blocked: 9.5 | Q-table: 3030\n"
          ]
        }
      ]
    }
  ]
}